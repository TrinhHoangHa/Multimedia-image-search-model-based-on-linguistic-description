import os
import torch
from PIL import Image
import clip

# ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a ·∫£nh (c√≥ th·ªÉ c√≥ th∆∞ m·ª•c con: Toyota, Honda,...)
IMAGE_DIR = "D:/DoAn/images"

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("clip_best.pt", device=device)

# --- Duy·ªát t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c con ---
image_paths = []
for root, dirs, files in os.walk(IMAGE_DIR):
    for file in files:
        if file.lower().endswith((".jpg", ".jpeg", ".png")):
            image_paths.append(os.path.join(root, file))

print(f"üîé T√¨m th·∫•y {len(image_paths)} ·∫£nh trong {IMAGE_DIR}")

# --- Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ·∫£nh ---
image_features = []
valid_image_paths = []

for path in image_paths:
    try:
        img = preprocess(Image.open(path).convert("RGB")).unsqueeze(0).to(device)
        with torch.no_grad():
            feat = model.encode_image(img)
            feat /= feat.norm(dim=-1, keepdim=True)
        image_features.append(feat)
        valid_image_paths.append(path)
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc ·∫£nh {path}: {e}")

if len(image_features) == 0:
    raise RuntimeError("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh h·ª£p l·ªá trong th∆∞ m·ª•c IMAGE_DIR")

image_features = torch.cat(image_features, dim=0)
image_paths = valid_image_paths

# --- H√†m t√¨m ki·∫øm ---
def search_images(query, top_k=5):
    with torch.no_grad():
        text = clip.tokenize([query]).to(device)
        text_features = model.encode_text(text)
        text_features /= text_features.norm(dim=-1, keepdim=True)

        similarity = (100.0 * text_features @ image_features.T).softmax(dim=-1)
        values, indices = similarity[0].topk(top_k)

    # Tr·∫£ v·ªÅ tuple (ƒë∆∞·ªùng d·∫´n ·∫£nh, ƒëi·ªÉm s·ªë)
    results = [(image_paths[i], float(values[j])) for j, i in enumerate(indices)]
    return results
